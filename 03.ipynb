{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26b7900e",
   "metadata": {},
   "source": [
    "### RAG : RAG with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a77ede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aff2c20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = \"postgresql+psycopg://langchain:langchain@localhost:6024/langchain\"\n",
    "\n",
    "# Load the document, split it into chunks\n",
    "raw_documents = TextLoader('./test.txt', encoding='utf-8').load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200)\n",
    "documents = text_splitter.split_documents(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6b2269c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings \n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "\n",
    "db = PGVector.from_documents(\n",
    "    documents, embeddings_model, connection=connection)\n",
    "\n",
    "# create retriever to retrieve 2 relevant documents\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afd92152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning continues to be a dynamic and evolving field, offering endless opportunities for innovation and improvement.\n",
      "\n",
      "머신러닝 소개\n",
      "머신러닝(ML)은 인공지능(AI)의 한 분야로, 명시적으로 프로그래밍하지 않고도 시스템이 경험을 통해 학습하고 개선할 수 있도록 합니다. 패턴을 식별하고 데이터를 기반으로 의사 결정을 내릴 수 있는 알고리즘을 개발하는 것을 포함합니다. 수년에 걸쳐 머신러닝은 의료, 금융, 소매, 기술 등 수많은 산업을 혁신해 왔습니다.\n",
      "\n",
      "머신러닝의 핵심 개념\n",
      "알고리즘: 머신러닝의 핵심은 데이터를 처리하고 이를 통해 학습하는 알고리즘입니다. 일반적인 알고리즘은 다음과 같습니다.\n",
      "\n",
      "지도 학습: 알고리즘은 레이블이 지정된 데이터를 기반으로 학습합니다. 선형 회귀, 서포트 벡터 머신(SVM), 신경망 등이 여기에 포함됩니다.\n",
      "비지도 학습: 알고리즘은 레이블이 지정되지 않은 데이터를 사용하여 패턴을 식별합니다. k-평균 군집화 및 주성분 분석(PCA) 등이 여기에 포함됩니다.\n",
      "강화 학습: 알고리즘은 환경과 상호 작용하고 보상 또는 페널티를 받아 학습합니다. Q-학습 및 심층 강화 학습이 여기에 포함됩니다.\n",
      "데이터: 데이터의 질과 양은 ML 모델의 성공에 매우 중요합니다. 데이터는 정형 데이터(예: 데이터베이스)이거나 비정형 데이터(예: 텍스트, 이미지)일 수 있습니다.\n",
      "\n",
      "학습 및 테스트:\n",
      "\n",
      "학습: 패턴을 학습하기 위해 ML 알고리즘에 데이터를 입력하는 프로세스입니다.\n",
      "테스트: 일반화 능력을 평가하기 위해 보이지 않는 데이터에 대한 모델의 성능을 평가합니다.\n",
      "모델 평가: 정확도, 정밀도, 재현율, F1 점수, 평균 제곱 오차(MSE)와 같은 다양한 지표를 사용하여 ML 모델을 평가합니다.\n"
     ]
    }
   ],
   "source": [
    "query = '머신러닝의 종류는 어떤 것들이 있어?'\n",
    "\n",
    "# fetch relevant documents\n",
    "docs = retriever.invoke(query)\n",
    "\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7cb880e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='머신러닝의 종류는 다음과 같습니다:\\n\\n1. **지도 학습**: 레이블이 지정된 데이터를 기반으로 학습하는 알고리즘입니다. 예: 선형 회귀, 서포트 벡터 머신(SVM), 신경망.\\n   \\n2. **비지도 학습**: 레이블이 지정되지 않은 데이터를 사용하여 패턴을 식별하는 알고리즘입니다. 예: k-평균 군집화, 주성분 분석(PCA).\\n\\n3. **강화 학습**: 알고리즘이 환경과 상호 작용하고 보상 또는 페널티를 받아 학습하는 방식입니다. 예: Q-학습, 심층 강화 학습.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 150, 'prompt_tokens': 1021, 'total_tokens': 1171, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BnzamUNQiO3fmqYPWm6FcMCJzModB', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--e10d5efc-1117-4809-9aad-eceef53fa918-0' usage_metadata={'input_tokens': 1021, 'output_tokens': 150, 'total_tokens': 1171, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Answer the question based only on the following context: {context} Question: {question} \"\"\"\n",
    ")\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "llm_chain = prompt | llm\n",
    "\n",
    "# answer the question based on relevant documents\n",
    "result = llm_chain.invoke({\"context\": docs, \"question\": query})\n",
    "\n",
    "print(result)\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88681f66",
   "metadata": {},
   "source": [
    "##### chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfad845a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "머신러닝의 종류는 다음과 같습니다:\n",
      "\n",
      "1. **지도 학습**: 레이블이 지정된 데이터를 기반으로 학습하는 알고리즘입니다. 예: 선형 회귀, 서포트 벡터 머신(SVM), 신경망.\n",
      "   \n",
      "2. **비지도 학습**: 레이블이 지정되지 않은 데이터를 사용하여 패턴을 식별하는 알고리즘입니다. 예: k-평균 군집화, 주성분 분석(PCA).\n",
      "\n",
      "3. **강화 학습**: 알고리즘이 환경과 상호 작용하고 보상 또는 페널티를 받아 학습하는 방식입니다. 예: Q-학습, 심층 강화 학습.\n"
     ]
    }
   ],
   "source": [
    "@chain\n",
    "def qa(input):\n",
    "    # fetch relevant documents\n",
    "    docs = retriever.invoke(input)\n",
    "    # format prompt\n",
    "    formatted = prompt.invoke({\"context\": docs, \"question\": input})\n",
    "    # generate answer\n",
    "    answer = llm.invoke(formatted)\n",
    "    return answer\n",
    "\n",
    "\n",
    "# run it\n",
    "result = qa.invoke(query)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff05fe67",
   "metadata": {},
   "source": [
    "##### Query Rewrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7e32b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "\n",
    "# See docker command above to launch a postgres instance with pgvector enabled.\n",
    "connection = \"postgresql+psycopg://langchain:langchain@localhost:6024/langchain\"\n",
    "\n",
    "# Load the document, split it into chunks\n",
    "raw_documents = TextLoader('./test.txt', encoding='utf-8').load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200)\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "\n",
    "# Create embeddings for the documents\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "\n",
    "db = PGVector.from_documents(\n",
    "    documents, embeddings_model, connection=connection)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a39605d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags=['PGVector', 'OpenAIEmbeddings'] vectorstore=<langchain_postgres.vectorstores.PGVector object at 0x0000017ED6E758B0> search_kwargs={'k': 2}\n"
     ]
    }
   ],
   "source": [
    "# create retriever to retrieve 2 relevant documents\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 2})\n",
    "print(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d1e688f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "헬스케어: 환자 결과 예측 분석, 개인 맞춤형 의료, 의료 영상 분석\n",
      "금융: 사기 탐지, 알고리즘 트레이딩, 신용 평가\n",
      "소매: 고객 세분화, 추천 시스템, 재고 관리\n",
      "기술: 자연어 처리(NLP), 컴퓨터 비전, 자율 시스템\n",
      "머신러닝의 과제\n",
      "머신러닝은 잠재력에도 불구하고 여러 과제에 직면합니다.\n",
      "\n",
      "데이터 품질: 품질이 낮은 데이터는 부정확한 모델로 이어질 수 있습니다.\n",
      "과대적합과 과소적합: 모델 복잡성의 균형을 맞춰 새로운 데이터에 대한 일반화가 잘 이루어지도록 합니다.\n",
      "해석성: 복잡한 모델이 어떻게 의사 결정을 내리는지 이해합니다.\n",
      "확장성: 대량의 데이터를 효율적으로 처리합니다.\n",
      "윤리적 고려 사항: 공정하고 편향되지 않은 모델 보장\n",
      "머신 러닝의 미래\n",
      "딥 러닝, 전이 학습, 강화 학습의 발전으로 머신 러닝의 미래는 밝습니다. 이러한 발전은 혁신을 더욱 촉진하고 더욱 정교한 애플리케이션을 구현할 것으로 예상됩니다. 또한, 사물 인터넷(IoT) 및 엣지 컴퓨팅과 같은 다른 기술과 머신 러닝을 통합하면 실시간 데이터 처리 및 의사 결정에 새로운 가능성이 열릴 것입니다.\n",
      "\n",
      "머신 러닝은 끊임없이 역동적이고 진화하는 분야로, 혁신과 개선을 위한 무한한 기회를 제공합니다.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query starts with irrelevant information before asking the relevant question\n",
    "query = '오늘 아침에 일어나 양치질을 하고 나서 뉴스를 읽으려고 앉았습니다. 그런데 밥솥에 음식을 두고 왔습니다. 머신러닝의 종류는 어떤 것들이 있어??'\n",
    "\n",
    "# fetch relevant documents\n",
    "docs = retriever.invoke(query)\n",
    "\n",
    "print(docs[0].page_content)\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f66b74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서에서는 머신러닝의 구체적인 종류에 대한 언급은 없지만, 머신러닝의 발전 방향으로 딥 러닝, 전이 학습, 강화 학습이 언급되고 있습니다. 이러한 기술들은 머신러닝의 중요한 분야로 간주됩니다.\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Answer the question based only on the following context: {context} Question: {question} \"\"\"\n",
    ")\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "@chain\n",
    "def qa(input):\n",
    "    # fetch relevant documents\n",
    "    docs = retriever.invoke(input)\n",
    "    # format prompt\n",
    "    formatted = prompt.invoke({\"context\": docs, \"question\": input})\n",
    "    # generate answer\n",
    "    answer = llm.invoke(formatted)\n",
    "    return answer\n",
    "\n",
    "\n",
    "# run it\n",
    "result = qa.invoke(query)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01f87fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Call model again with rewritten query\n",
      "\n",
      "Rewritten query:  머신러닝 종류 개요, 지도학습 비지도학습 강화학습 차이점\"\n",
      "머신러닝의 종류에는 다음과 같은 세 가지 주요 유형이 있습니다:\n",
      "\n",
      "1. **지도 학습**: 알고리즘이 레이블이 지정된 데이터를 기반으로 학습합니다. 예를 들어, 선형 회귀, 서포트 벡터 머신(SVM), 신경망 등이 있습니다.\n",
      "\n",
      "2. **비지도 학습**: 알고리즘이 레이블이 지정되지 않은 데이터를 사용하여 패턴을 식별합니다. 예를 들어, k-평균 군집화 및 주성분 분석(PCA) 등이 있습니다.\n",
      "\n",
      "3. **강화 학습**: 알고리즘이 환경과 상호 작용하고 보상 또는 페널티를 받아 학습합니다. 예를 들어, Q-학습 및 심층 강화 학습이 있습니다.\n"
     ]
    }
   ],
   "source": [
    "rewrite_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Provide a better search query for web search engine to answer the given question, end the queries with ’**’. Question: {x} Answer:\"\"\")\n",
    "\n",
    "\n",
    "def parse_rewriter_output(message):\n",
    "    return message.content.strip('\"').strip(\"**\")\n",
    "\n",
    "\n",
    "rewriter = rewrite_prompt | llm | parse_rewriter_output\n",
    "\n",
    "\n",
    "@chain\n",
    "def qa_rrr(input):\n",
    "    # rewrite the query\n",
    "    new_query = rewriter.invoke(input)\n",
    "    print(\"Rewritten query: \", new_query)\n",
    "    # fetch relevant documents\n",
    "    docs = retriever.invoke(new_query)\n",
    "    # format prompt\n",
    "    formatted = prompt.invoke({\"context\": docs, \"question\": input})\n",
    "    # generate answer\n",
    "    answer = llm.invoke(formatted)\n",
    "    return answer\n",
    "\n",
    "\n",
    "print(\"\\nCall model again with rewritten query\\n\")\n",
    "\n",
    "# call model again with rewritten query\n",
    "result = qa_rrr.invoke(query)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81fa93d",
   "metadata": {},
   "source": [
    "##### Multi Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81bab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "\n",
    "# See docker command above to launch a postgres instance with pgvector enabled.\n",
    "connection = \"postgresql+psycopg://langchain:langchain@localhost:6024/langchain\"\n",
    "\n",
    "# Load the document, split it into chunks\n",
    "raw_documents = TextLoader('./test.txt', encoding='utf-8').load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200)\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "\n",
    "# Create embeddings for the documents\n",
    "embeddings_model = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9410c0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = PGVector.from_documents(\n",
    "    documents, embeddings_model, connection=connection)\n",
    "\n",
    "# create retriever to retrieve 2 relevant documents\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "324f0678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instruction to generate multiple queries\n",
    "perspectives_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"당신은 AI 언어 모델 어시스턴트입니다. 주어진 사용자 질문에 대해 다섯 가지 다른 버전을 생성하여 벡터 데이터베이스에서 관련 문서를 검색하는 것이 당신의 임무입니다.\n",
    "        사용자 질문에 대한 다양한 관점을 생성함으로써, 당신의 목표는 사용자가 거리 기반 유사성 검색의 한계를 극복하도록 돕는 것입니다.\n",
    "        다음과 같은 대안 질문들을 줄바꿈으로 구분하여 제공하세요. \n",
    "    Original question: {question}\"\"\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "\n",
    "def parse_queries_output(message):\n",
    "    return message.content.split('\\n')\n",
    "\n",
    "\n",
    "query_gen = perspectives_prompt | llm | parse_queries_output\n",
    "\n",
    "\n",
    "def get_unique_union(document_lists):\n",
    "    # Flatten list of lists, and dedupe them\n",
    "    deduped_docs = {\n",
    "        doc.page_content: doc for sublist in document_lists for doc in sublist}\n",
    "    # return a flat list of unique docs\n",
    "    return list(deduped_docs.values())\n",
    "\n",
    "\n",
    "retrieval_chain = query_gen | retriever.batch | get_unique_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9bc0af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running multi query qa\n",
      "\n",
      "머신러닝의 종류로는 다음과 같은 것들이 있습니다:\n",
      "\n",
      "1. **지도 학습**: 레이블이 지정된 데이터를 기반으로 학습하는 알고리즘입니다. 예: 선형 회귀, 서포트 벡터 머신(SVM), 신경망.\n",
      "   \n",
      "2. **비지도 학습**: 레이블이 지정되지 않은 데이터를 사용하여 패턴을 식별하는 알고리즘입니다. 예: k-평균 군집화, 주성분 분석(PCA).\n",
      "\n",
      "3. **강화 학습**: 알고리즘이 환경과 상호 작용하고 보상 또는 페널티를 받아 학습하는 방식입니다. 예: Q-학습, 심층 강화 학습.\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Answer the question based only on the following context: {context} Question: {question} \"\"\"\n",
    ")\n",
    "\n",
    "query = \"머신러닝의 종류는 어떤 것들이 있어?\"\n",
    "\n",
    "\n",
    "@chain\n",
    "def multi_query_qa(input):\n",
    "    # fetch relevant documents\n",
    "    docs = retrieval_chain.invoke(input)  # format prompt\n",
    "    formatted = prompt.invoke(\n",
    "        {\"context\": docs, \"question\": input})  # generate answer\n",
    "    answer = llm.invoke(formatted)\n",
    "    return answer\n",
    "\n",
    "\n",
    "# run\n",
    "print(\"Running multi query qa\\n\")\n",
    "result = multi_query_qa.invoke(query)\n",
    "print(result.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcc8f39",
   "metadata": {},
   "source": [
    "#### RAG Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e92549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "# See docker command above to launch a postgres instance with pgvector enabled.\n",
    "connection = \"postgresql+psycopg://langchain:langchain@localhost:6024/langchain\"\n",
    "\n",
    "# Load the document, split it into chunks\n",
    "raw_documents = TextLoader('./test.txt', encoding='utf-8').load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200)\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "\n",
    "# Create embeddings for the documents\n",
    "embeddings_model = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d25c0956",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = PGVector.from_documents(\n",
    "    documents, embeddings_model, connection=connection)\n",
    "\n",
    "# create retriever to retrieve 2 relevant documents\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "prompt_rag_fusion = ChatPromptTemplate.from_template(\n",
    "    \"\"\"단일 입력 쿼리를 기반으로 여러 검색어를 생성하는 유용한 도우미입니다. \n",
    "        다음과 관련된 여러 검색어를 생성합니다.: {question} \n",
    "        Output (4 queries):\"\"\")\n",
    "\n",
    "\n",
    "def parse_queries_output(message):\n",
    "    return message.content.split('\\n')\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "query_gen = prompt_rag_fusion | llm | parse_queries_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34d9b2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated queries:  ['1. Supervised learning types in machine learning', '2. Unsupervised learning types in machine learning', '3. Reinforcement learning types in machine learning', '4. Semi-supervised learning types in machine learning']\n"
     ]
    }
   ],
   "source": [
    "query = \"머신러닝의 종류는 어떤 것들이 있어?\"\n",
    "\n",
    "generated_queries = query_gen.invoke(query)\n",
    "\n",
    "print(\"generated queries: \", generated_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79c5ddd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved context using rank fusion:  Key Concepts in Machine Learning\n",
      "Algorithms: At the core of machine learning are algorithms that process data and learn from it. Common algorithms include:\n",
      "\n",
      "Supervised Learning: Algorithms are trained on labeled data. Examples include linear regression, support vector machines (SVM), and neural networks.\n",
      "Unsupervised Learning: Algorithms are used on unlabeled data to identify patterns. Examples include k-means clustering and principal component analysis (PCA).\n",
      "Reinforcement Learning: Algorithms learn by interacting with the environment and receiving rewards or penalties. Examples include Q-learning and deep reinforcement learning.\n",
      "Data: The quality and quantity of data are critical to the success of ML models. Data can be structured (e.g., databases) or unstructured (e.g., text, images).\n",
      "\n",
      "Training and Testing:\n",
      "\n",
      "\n",
      "\n",
      "Use model to answer question based on retrieved docs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "we fetch relevant documents for each query and pass them into a function to rerank (that is, reorder according to relevancy) the final list of relevant documents.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def reciprocal_rank_fusion(results: list[list], k=60):\n",
    "    \"\"\"reciprocal rank fusion on multiple lists of ranked documents and an optional parameter k used in the RRF formula\"\"\"\n",
    "    # Initialize a dictionary to hold fused scores for each document\n",
    "    # Documents will be keyed by their contents to ensure uniqueness\n",
    "    fused_scores = {}\n",
    "    documents = {}\n",
    "    for docs in results:\n",
    "        # Iterate through each document in the list, with its rank (position in the list)\n",
    "        for rank, doc in enumerate(docs):\n",
    "            doc_str = doc.page_content\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "                documents[doc_str] = doc\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "    # sort the documents based on their fused scores in descending order to get the final reranked results\n",
    "    reranked_doc_strs = sorted(\n",
    "        fused_scores, key=lambda d: fused_scores[d], reverse=True)\n",
    "    return [documents[doc_str] for doc_str in reranked_doc_strs]\n",
    "\n",
    "\n",
    "retrieval_chain = query_gen | retriever.batch | reciprocal_rank_fusion\n",
    "\n",
    "result = retrieval_chain.invoke(query)\n",
    "\n",
    "print(\"retrieved context using rank fusion: \", result[0].page_content)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(\"Use model to answer question based on retrieved docs\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b97163c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running rag fusion\n",
      "\n",
      "딥 러닝, 전이 학습, 강화 학습\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Answer the question based only on the following context: {context} Question: {question} \"\"\"\n",
    ")\n",
    "\n",
    "query = \"잘 알려지지 않았지만 최근에 만들어진 머신러닝의 종류는 어떤 것들이 있어?\"\n",
    "\n",
    "\n",
    "@chain\n",
    "def rag_fusion(input):\n",
    "    # fetch relevant documents\n",
    "    docs = retrieval_chain.invoke(input)  # format prompt\n",
    "    formatted = prompt.invoke(\n",
    "        {\"context\": docs, \"question\": input})  # generate answer\n",
    "    answer = llm.invoke(formatted)\n",
    "    return answer\n",
    "\n",
    "\n",
    "# run\n",
    "print(\"Running rag fusion\\n\")\n",
    "result = rag_fusion.invoke(query)\n",
    "print(result.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b7cd14",
   "metadata": {},
   "source": [
    "##### HyDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdfd30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import chain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# See docker command above to launch a postgres instance with pgvector enabled.\n",
    "connection = \"postgresql+psycopg://langchain:langchain@localhost:6024/langchain\"\n",
    "\n",
    "# Load the document, split it into chunks\n",
    "raw_documents = TextLoader('./test.txt', encoding='utf-8').load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200)\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "\n",
    "# Create embeddings for the documents\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "\n",
    "db = PGVector.from_documents(\n",
    "    documents, embeddings_model, connection=connection)\n",
    "\n",
    "# create retriever to retrieve 2 relevant documents\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "prompt_hyde = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Please write a passage to answer the question.\\n Question: {question} \\n Passage:\"\"\")\n",
    "\n",
    "generate_doc = (prompt_hyde | ChatOpenAI(temperature=0) | StrOutputParser())\n",
    "\n",
    "\"\"\"\n",
    "Next, we take the hypothetical document generated above and use it as input to the retriever, \n",
    "which will generate its embedding and search for similar documents in the vector store:\n",
    "\"\"\"\n",
    "retrieval_chain = generate_doc | retriever\n",
    "\n",
    "query = \"머신러닝의 종류는 어떤 것들이 있어?\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Answer the question based only on the following context: {context} Question: {question} \"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "\n",
    "@chain\n",
    "def qa(input):\n",
    "    # fetch relevant documents from the hyde retrieval chain defined earlier\n",
    "    docs = retrieval_chain.invoke(input)\n",
    "    # format prompt\n",
    "    formatted = prompt.invoke({\"context\": docs, \"question\": input})\n",
    "    # generate answer\n",
    "    answer = llm.invoke(formatted)\n",
    "    return answer\n",
    "\n",
    "\n",
    "print(\"Running hyde\\n\")\n",
    "result = qa.invoke(query)\n",
    "print(\"\\n\\n\")\n",
    "print(result.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444c77f4",
   "metadata": {},
   "source": [
    "### Query Routing\n",
    "\n",
    "  - Logical Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "956a3456",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f034cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data model class\n",
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"Route a user query to the most relevant datasource.\"\"\"\n",
    "    datasource: Literal[\"python_docs\", \"js_docs\"] = Field(\n",
    "        ...,\n",
    "        description=\"Given a user question, choose which datasource would be most relevant for answering their question\",\n",
    "    )\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "\"\"\"\n",
    "with_structured_output: Model wrapper that returns outputs formatted to match the given schema.\n",
    "\n",
    "\"\"\"\n",
    "structured_llm = llm.with_structured_output(RouteQuery)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"사용자 질문을 적절한 데이터 소스로 라우팅하는 전문가입니다.\n",
    "            질문이 참조하는 프로그래밍 언어에 따라 관련 데이터 소스로 라우팅하세요.\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system), (\"human\", \"{question}\")]\n",
    ")\n",
    "\n",
    "# Define router\n",
    "router = prompt | structured_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18ebc71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Routing to:  datasource='python_docs'\n",
      "\n",
      "Choose route:  chain for python_docs\n"
     ]
    }
   ],
   "source": [
    "# Run\n",
    "question = \"\"\"다음의 코드가 동작하지 않는 이유는 무엇입니까?: \n",
    "                from langchain_core.prompts \n",
    "                import ChatPromptTemplate \n",
    "                prompt = ChatPromptTemplate.from_messages([\"human\", \"speak in {language}\"]) \n",
    "                prompt.invoke(\"french\") \"\"\"\n",
    "\n",
    "result = router.invoke({\"question\": question})\n",
    "print(\"\\nRouting to: \", result)\n",
    "\n",
    "\"\"\"\n",
    "Once we extracted the relevant data source, we can pass the value into another function to execute additional logic as required:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def choose_route(result):\n",
    "    if \"python_docs\" in result.datasource.lower():\n",
    "        return \"chain for python_docs\"\n",
    "    else:\n",
    "        return \"chain for js_docs\"\n",
    "\n",
    "\n",
    "full_chain = router | RunnableLambda(choose_route)\n",
    "\n",
    "result = full_chain.invoke({\"question\": question})\n",
    "print(\"\\nChoose route: \", result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13292010",
   "metadata": {},
   "source": [
    "##### Semantic Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c5c91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utils.math import cosine_similarity\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import chain\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "physics_template = \"\"\"당신은 매우 똑똑한 물리학자입니다. 물리학 관련 질문에 간결하고 이해하기 쉬운 답을 주세요. \n",
    "                        질문에 대한 답을 모르면 \"모릅니다\"로 답변을 주세요. 여기 질문이 있습니다.: {query}\"\"\"\n",
    "math_template = \"\"\"당신은 우수한 수학자입니다. 수학 문제에 매우 익숙합니다. 어려운 문제를 구성 요소로 분해하고,\n",
    "                        그 구성 요소에 답하고, 다시 종합하여 더 복잡한 문제에 대한 답을 찾을 수 있습니다.\n",
    "                        여기 질문이 있습니다.: {query}\"\"\"\n",
    "\n",
    "# Embed prompts\n",
    "embeddings = OpenAIEmbeddings()\n",
    "prompt_templates = [physics_template, math_template]\n",
    "prompt_embeddings = embeddings.embed_documents(prompt_templates)\n",
    "\n",
    "# Route question to prompt\n",
    "\n",
    "\n",
    "@chain\n",
    "def prompt_router(query):\n",
    "    query_embedding = embeddings.embed_query(query)\n",
    "    similarity = cosine_similarity([query_embedding], prompt_embeddings)[0]\n",
    "    most_similar = prompt_templates[similarity.argmax()]\n",
    "    print(\"Using MATH\" if most_similar == math_template else \"Using PHYSICS\")\n",
    "    return PromptTemplate.from_template(most_similar)\n",
    "\n",
    "\n",
    "semantic_router = (prompt_router | ChatOpenAI() | StrOutputParser())\n",
    "\n",
    "result = semantic_router.invoke(\"What's a black hole\")\n",
    "print(\"\\nSemantic router result: \", result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054b48c3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
