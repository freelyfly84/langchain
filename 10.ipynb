{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0160b58a",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308e3ba8",
   "metadata": {},
   "source": [
    "##### The Design 단계 : Self-Corrective RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64a12ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: \n",
      " [Document(id='43c1d910-9305-4d42-b05a-77a928b41049', metadata={'source': 'https://blog.langchain.dev/top-5-langgraph-agents-in-production-2024/', 'title': 'Top 5 LangGraph Agents in Production 2024', 'language': 'en'}, page_content='Top 5 LangGraph Agents in Production 2024\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCase Studies\\n\\n\\n\\n\\nIn the Loop\\n\\n\\n\\n\\nLangChain\\n\\n\\n\\n\\nDocs\\n\\n\\n\\n\\nChangelog\\n\\n\\n\\n\\n\\nSign in\\nSubscribe\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTop 5 LangGraph Agents in Production 2024\\n\\n3 min read\\nDec 31, 2024'), Document(id='87e5c51e-ac00-4001-8054-161c0bd3aec2', metadata={'source': 'https://blog.langchain.dev/top-5-langgraph-agents-in-production-2024/', 'title': 'Top 5 LangGraph Agents in Production 2024', 'language': 'en'}, page_content='2024 was the year that agents started to work in production. Not the wide-ranging, fully autonomous agents that people imagined with AutoGPT. But more vertical, narrowly scoped, highly controllable agents with custom cognitive architectures. It\\'s still not easy to build these agents - but it\\'s entirely possible.We launched LangGraph in early 2024 as a new take on an agentic framework. Incorporating lessons learned from LangChain, we made LangGraph very low level, controllable agentic framework. No hidden prompts, no obfuscated \"cognitive architecture\". Soon after it\\'s launch, we saw LangGraph become the go-to default framework for agents.As the year closes, we wanted to highlight some of our favorite stories of companies building agents with LangGraph. As mentioned before, it\\'s still hard to build agents, but these companies have figured out how. They\\'ve shared their lessons learned in various forms - blogs, case studies, talks, fireside chats. We hope that by amplifying their stories, their lessons learned, it enables every more agents to be built in 2025.Honorable mentions:Unify: An agent for GTM account qualification, featuring o1 as a planning'), Document(id='3e6119a3-6a99-4019-b78c-b89feb630c53', metadata={'source': 'https://blog.langchain.dev/langchain-state-of-ai-2024/', 'title': 'LangChain State of AI 2024 Report', 'description': 'Dive into LangSmith product usage patterns that show how the AI ecosystem and the way people are building LLM apps is evolving.', 'language': 'en'}, page_content='agent framework, LangGraph, is also on the rise. Since its release in March 2024, LangGraph has steadily gained traction —\\xa0with 43% of LangSmith organizations are now sending LangGraph traces. These traces represent complex, orchestrated tasks that go beyond basic LLM interactions.This growth aligns with the rise in agentic behavior: we see that on average 21.9% of traces now involve tool calls, up from an average of 0.5% in 2023. Tool calling allows a model to autonomously invoke functions or external resources, signaling more agentic behavior where the model decides when to take action. Increased use of tool calling can enhance an agent’s ability to interact with external systems and perform tasks like writing to databases.\\xa0Performance and optimizationBalancing speed and sophistication is a key challenge when developing applications — especially those leveraging LLM resources. Below, we explore how organizations are interacting with their applications to align the complexity of their needs with efficient performance.Complexity is growing, but tasks are being handled efficiently\\xa0\\xa0The average number of steps per trace has more than doubled over the past year, rising from on average 2.8 steps (2023) to 7.7 steps (2024). We define'), Document(id='71c33814-9026-4b49-952f-5b2cfe9b5d90', metadata={'source': 'https://blog.langchain.dev/top-5-langgraph-agents-in-production-2024/', 'title': 'Top 5 LangGraph Agents in Production 2024', 'language': 'en'}, page_content='AppFolioAppFolio\\'s AI-powered copilot Realm-X has saved property managers over 10 hours per week. Realm-X provides a conversational interface that helps users understand the state of their business, get help, and execute actions in bulk – whether it’s querying information, sending messages, or scheduling actions related to residents, vendors, units, bills, or work orders and many moreOn their journey, they needed a controllable agent architecture to make this a reality — and so they chose LangGraphCase study#3: LinkedInOne of the big use cases for LLMs is in making data more accessible to everyone. LinkedIn recently rolled out SQL Bot, an AI-powered assistant internallyThis internal tool transforms natural language questions into SQL: it finds the right tables, writes queries, fixes errors, and enables employees across functions to independently access the data insights they need under the appropriate permissions.Behind the scenes, SQL Bot is a multi-agent system built on top of LangChain and LangGraph.LinkedIn Engineering Blog#2: ElasticElastic was one of the first companies in my mind to launch an AI \"agent\". We covered their AI assistant in late January of 2024 - right at the start of the')]\n",
      "\n",
      "\n",
      "Grade Result: \n",
      " binary_score='yes'\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import InMemoryVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# --- Create an index of documents ---\n",
    "\n",
    "urls = [\n",
    "    \"https://blog.langchain.dev/top-5-langgraph-agents-in-production-2024/\",\n",
    "    \"https://blog.langchain.dev/langchain-state-of-ai-2024/\",\n",
    "    \"https://blog.langchain.dev/introducing-ambient-agents/\",\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = InMemoryVectorStore.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Retrieve the relevant documents\n",
    "results = retriever.invoke(\n",
    "    \"What are 2 LangGraph agents used in production in 2024?\")\n",
    "\n",
    "print(\"Results: \\n\", results)\n",
    "\n",
    "\n",
    "# --- Create a grader for retrieved documents ---\n",
    "\n",
    "# Data model\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM with structured output\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question.\n",
    "If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant.\n",
    "Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
    "\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\",\n",
    "         \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retrieval_grader = grade_prompt | structured_llm_grader\n",
    "\n",
    "# --- Grade retrieved documents ---\n",
    "\n",
    "question = \"What are 2 LangGraph agents used in production in 2024?\"\n",
    "\n",
    "# as an example retrieval_grader.invoke({\"question\": question, \"document\": doc_txt})\n",
    "docs = retriever.invoke(question)\n",
    "\n",
    "doc_txt = docs[0].page_content\n",
    "\n",
    "result = retrieval_grader.invoke({\"question\": question, \"document\": doc_txt})\n",
    "\n",
    "print(\"\\n\\nGrade Result: \\n\", result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f392afc1",
   "metadata": {},
   "source": [
    "##### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd4e6ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created in langsmith with ID: 31147dab-5af7-48e1-8c42-c0079e0a3d8a\n",
      " Navigate to https://smith.langchain.com/o/131371ab-0bf2-4ad3-88cd-3b2d53ea1af9/datasets/31147dab-5af7-48e1-8c42-c0079e0a3d8a.\n"
     ]
    }
   ],
   "source": [
    "from langsmith import wrappers, Client\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "\n",
    "client = Client()\n",
    "openai_client = wrappers.wrap_openai(OpenAI())\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"Which companies are highlighted as top LangGraph agent adopters in 2024?\",\n",
    "        \"answer\": \"The top adopters include Uber (code migration tools), AppFolio (property management copilot), LinkedIn (SQL Bot), Elastic (AI assistant), and Replit (multi-agent development platform) :cite[3].\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How did AppFolio's AI copilot impact property managers?\",\n",
    "        \"answer\": \"AppFolio's Realm-X AI copilot saved property managers over 10 hours per week by automating queries, bulk actions, and scheduling :cite[3].\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What infrastructure trends dominated LLM usage in 2024?\",\n",
    "        \"answer\": \"OpenAI remained the top LLM provider (6x more usage than Ollama), while open-source models via Ollama and Groq surged. Chroma and FAISS led vector stores, with MongoDB and Elastic gaining traction :cite[2]:cite[5].\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How did LangGraph improve agent workflows compared to 2023?\",\n",
    "        \"answer\": \"LangGraph usage grew to 43% of LangSmith organizations, with 21.9% of traces involving tool calls (up from 0.5% in 2023), enabling complex multi-step tasks like database writes :cite[2]:cite[7].\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What distinguishes Replit's LangGraph implementation?\",\n",
    "        \"answer\": \"Replit's agent emphasizes human-in-the-loop validation and a multi-agent architecture for code generation, combining autonomy with controlled outputs :cite[3].\"\n",
    "    }\n",
    "]\n",
    "\n",
    "inputs = [{\"question\": example[\"question\"]} for example in examples]\n",
    "outputs = [{\"answer\": example[\"answer\"]} for example in examples]\n",
    "\n",
    "# Programmatically create a dataset in LangSmith\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name=\"langgraph-blogs-qa\", description=\"Langchain blogs QA.\"\n",
    ")\n",
    "\n",
    "# Add examples to the dataset\n",
    "client.create_examples(inputs=inputs, outputs=outputs, dataset_id=dataset.id)\n",
    "\n",
    "print(\n",
    "    f\"Dataset created in langsmith with ID: {dataset.id}\\n Navigate to {dataset.url}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
