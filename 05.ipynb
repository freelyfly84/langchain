{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "259ff1fa",
   "metadata": {},
   "source": [
    "### Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feeb884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    answer = model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [answer]}\n",
    "\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "builder.add_edge(START, \"chatbot\")\n",
    "builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# Example usage\n",
    "\n",
    "input = {\"messages\": [HumanMessage(\"hi!\")]}\n",
    "for chunk in graph.stream(input):\n",
    "    print(chunk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f07a2bc",
   "metadata": {},
   "source": [
    "### Chain\n",
    "\n",
    "미리 정의된 순서로 여러 LLM 호출을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55068f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# useful to generate SQL query\n",
    "model_low_temp = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.1)\n",
    "# useful to generate natural language outputs\n",
    "model_high_temp = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.7)\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    # to track conversation history\n",
    "    messages: Annotated[list, add_messages]\n",
    "    # input\n",
    "    user_query: str\n",
    "    # output\n",
    "    sql_query: str\n",
    "    sql_explanation: str\n",
    "\n",
    "\n",
    "class Input(TypedDict):\n",
    "    user_query: str\n",
    "\n",
    "\n",
    "class Output(TypedDict):\n",
    "    sql_query: str\n",
    "    sql_explanation: str\n",
    "\n",
    "\n",
    "generate_prompt = SystemMessage(\n",
    "    \"당신은 사용자의 질문에 따라 SQL 쿼리를 생성하는 유용한 데이터 분석가입니다.\"\n",
    ")\n",
    "\n",
    "\n",
    "def generate_sql(state: State) -> State:\n",
    "    user_message = HumanMessage(state[\"user_query\"])\n",
    "    messages = [generate_prompt, *state[\"messages\"], user_message]\n",
    "    res = model_low_temp.invoke(messages)\n",
    "    return {\n",
    "        \"sql_query\": res.content,\n",
    "        # update conversation history\n",
    "        \"messages\": [user_message, res],\n",
    "    }\n",
    "\n",
    "\n",
    "explain_prompt = SystemMessage(\n",
    "    \"당신은 사용자에게 SQL을 쿼리를 설명하는 유용한 데이터 분석가입니다.\"\n",
    ")\n",
    "\n",
    "\n",
    "def explain_sql(state: State) -> State:\n",
    "    messages = [\n",
    "        explain_prompt,\n",
    "        # contains user's query and SQL query from prev step\n",
    "        *state[\"messages\"],\n",
    "    ]\n",
    "    res = model_high_temp.invoke(messages)\n",
    "    return {\n",
    "        \"sql_explanation\": res.content,\n",
    "        # update conversation history\n",
    "        \"messages\": res,\n",
    "    }\n",
    "\n",
    "\n",
    "builder = StateGraph(State, input=Input, output=Output)\n",
    "builder.add_node(\"generate_sql\", generate_sql)\n",
    "builder.add_node(\"explain_sql\", explain_sql)\n",
    "builder.add_edge(START, \"generate_sql\")\n",
    "builder.add_edge(\"generate_sql\", \"explain_sql\")\n",
    "builder.add_edge(\"explain_sql\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# Example usage\n",
    "result = graph.invoke({\"user_query\": \"각 제품의 총 매출은 얼마입니까?\"})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b134a900",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        graph.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc474ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal, TypedDict\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.vectorstores.in_memory import InMemoryVectorStore\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.graph.message import add_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e02196",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "# useful to generate SQL query\n",
    "model_low_temp = ChatOpenAI(temperature=0.1)\n",
    "# useful to generate natural language outputs\n",
    "model_high_temp = ChatOpenAI(temperature=0.7)\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    # to track conversation history\n",
    "    messages: Annotated[list, add_messages]\n",
    "    # input\n",
    "    user_query: str\n",
    "    # output\n",
    "    domain: Literal[\"records\", \"insurance\"]\n",
    "    documents: list[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "class Input(TypedDict):\n",
    "    user_query: str\n",
    "\n",
    "\n",
    "class Output(TypedDict):\n",
    "    documents: list[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a47fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Sample documents for testing\n",
    "sample_docs = [\n",
    "    Document(page_content=\"환자 진료 기록...\", metadata={\"domain\": \"records\"}),\n",
    "    Document(\n",
    "        page_content=\"보험 정책 세부 정보...\", metadata={\"domain\": \"insurance\"}\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Initialize vector stores\n",
    "medical_records_store = InMemoryVectorStore.from_documents(sample_docs, embeddings)\n",
    "medical_records_retriever = medical_records_store.as_retriever()\n",
    "\n",
    "insurance_faqs_store = InMemoryVectorStore.from_documents(sample_docs, embeddings)\n",
    "insurance_faqs_retriever = insurance_faqs_store.as_retriever()\n",
    "\n",
    "router_prompt = SystemMessage(\n",
    "    \"\"\"사용자 쿼리를 어떤 도메인으로 라우팅할지 결정해야 합니다. 다음 두 가지 도메인 중에서 선택할 수 있습니다.\n",
    "        - 기록: 진단, 치료, 처방전 등 환자의 의료 기록을 포함합니다.\n",
    "        - 보험: 보험 정책, 청구 및 보장 범위에 대한 자주 묻는 질문을 포함합니다.\n",
    "\n",
    "        도메인 이름만 출력합니다.\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "def router_node(state: State) -> State:\n",
    "    user_message = HumanMessage(state[\"user_query\"])\n",
    "    messages = [router_prompt, *state[\"messages\"], user_message]\n",
    "    res = model_low_temp.invoke(messages)\n",
    "    return {\n",
    "        \"domain\": res.content,\n",
    "        # update conversation history\n",
    "        \"messages\": [user_message, res],\n",
    "    }\n",
    "\n",
    "\n",
    "def pick_retriever(\n",
    "    state: State,\n",
    ") -> Literal[\"retrieve_medical_records\", \"retrieve_insurance_faqs\"]:\n",
    "    if state[\"domain\"] == \"records\":\n",
    "        return \"retrieve_medical_records\"\n",
    "    else:\n",
    "        return \"retrieve_insurance_faqs\"\n",
    "\n",
    "\n",
    "def retrieve_medical_records(state: State) -> State:\n",
    "    documents = medical_records_retriever.invoke(state[\"user_query\"])\n",
    "    return {\n",
    "        \"documents\": documents,\n",
    "    }\n",
    "\n",
    "\n",
    "def retrieve_insurance_faqs(state: State) -> State:\n",
    "    documents = insurance_faqs_retriever.invoke(state[\"user_query\"])\n",
    "    return {\n",
    "        \"documents\": documents,\n",
    "    }\n",
    "\n",
    "\n",
    "medical_records_prompt = SystemMessage(\n",
    "    \"당신은 환자의 진료 기록(진단, 치료, 처방 등)을 기반으로 환자의 질문에 답하는 유용한 의료 챗봇입니다.\"\n",
    ")\n",
    "\n",
    "insurance_faqs_prompt = SystemMessage(\n",
    "    \"당신은 보험 정책, 청구 및 보장에 대한 자주 묻는 질문에 답변하는 유용한 의료 보험 챗봇입니다.\"\n",
    ")\n",
    "\n",
    "\n",
    "def generate_answer(state: State) -> State:\n",
    "    if state[\"domain\"] == \"records\":\n",
    "        prompt = medical_records_prompt\n",
    "    else:\n",
    "        prompt = insurance_faqs_prompt\n",
    "    messages = [\n",
    "        prompt,\n",
    "        *state[\"messages\"],\n",
    "        HumanMessage(f\"Documents: {state['documents']}\"),\n",
    "    ]\n",
    "    res = model_high_temp.invoke(messages)\n",
    "    return {\n",
    "        \"answer\": res.content,\n",
    "        # update conversation history\n",
    "        \"messages\": res,\n",
    "    }\n",
    "\n",
    "\n",
    "builder = StateGraph(State, input=Input, output=Output)\n",
    "builder.add_node(\"router\", router_node)\n",
    "builder.add_node(\"retrieve_medical_records\", retrieve_medical_records)\n",
    "builder.add_node(\"retrieve_insurance_faqs\", retrieve_insurance_faqs)\n",
    "builder.add_node(\"generate_answer\", generate_answer)\n",
    "builder.add_edge(START, \"router\")\n",
    "builder.add_conditional_edges(\"router\", pick_retriever)\n",
    "builder.add_edge(\"retrieve_medical_records\", \"generate_answer\")\n",
    "builder.add_edge(\"retrieve_insurance_faqs\", \"generate_answer\")\n",
    "builder.add_edge(\"generate_answer\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# Example usage\n",
    "input = {\"user_query\": \"Am I covered for COVID-19 treatment?\"}\n",
    "for chunk in graph.stream(input):\n",
    "    print(chunk)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
